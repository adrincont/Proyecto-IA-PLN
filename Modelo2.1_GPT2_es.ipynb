{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHkYFOFNvqi-"
      },
      "source": [
        "# **Modelo 2 (Generacion de Poemas) GPT2**\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers -U"
      ],
      "metadata": {
        "id": "WGXNdxfBLrwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2SAgacGzvqjB"
      },
      "outputs": [],
      "source": [
        "# Basicas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "# Pytorch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "# Texto\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import random\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm, trange\n",
        "from transformers import pipeline\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Datos**"
      ],
      "metadata": {
        "id": "J1yX23FRe0yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/andreamorgar/poesIA/master/data/poems.csv'\n",
        "poems_df = pd.read_csv(url)\n",
        "poems_df = poems_df.dropna()"
      ],
      "metadata": {
        "id": "1YLm8TDBezt-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar poemas grandes\n",
        "poems_df['string'] = poems_df.apply(lambda row: f'\\n{row[\"title\"]}\\n{row[\"content\"]}', axis=1)\n",
        "poems_df['length'] = poems_df.string.map(len)\n",
        "MAX_POEM_LENGTH=1000\n",
        "poems_filtered = poems_df[poems_df.length<MAX_POEM_LENGTH]\n",
        "#_ , poems_filtered = train_test_split(poems_filtered, test_size = 0.5 ,shuffle=True)\n",
        "poems_filtered"
      ],
      "metadata": {
        "id": "1g4lr7TxghDE",
        "outputId": "84cea515-0a2d-4ea0-9d87-9198862d2295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       author  \\\n",
              "1             Marilina Rébora   \n",
              "2             Antonio Colinas   \n",
              "3         José María Hinojosa   \n",
              "4     Rubén Izaguirre Fiallos   \n",
              "5       Leopoldo María Panero   \n",
              "...                       ...   \n",
              "5127           Ángel González   \n",
              "5129    David Escobar Galindo   \n",
              "5130                  amistad   \n",
              "5131              Octavio Paz   \n",
              "5132       José Ángel Valente   \n",
              "\n",
              "                                                content  \\\n",
              "1     \\n\\nPorque si tú no velas, vendré como ladrón;...   \n",
              "2     \\n\\nPequeña de mis sueños, por tu piel las pal...   \n",
              "3     \\n\\nLos dedos de la nieve\\nrepiquetearon\\nen e...   \n",
              "4     Naciste en Armenia,\\npero te fuiste a vivir al...   \n",
              "5     \\n\\nOscuridad nieve buitres desespero oscurida...   \n",
              "...                                                 ...   \n",
              "5127  \\n\\nCruzas por el crepúsculo.\\nEl aire\\ntienes...   \n",
              "5129  \\n\\nNada es memoria: todo es invención.\\nLo qu...   \n",
              "5130  \\nFelicidad: Muy dentro de tí.\\nSerenidad: En ...   \n",
              "5131  \\nMis manos \\nabren las cortinas de tu ser \\nt...   \n",
              "5132  \\n\\nY ahora danos\\nuna muerte honorable,\\nviej...   \n",
              "\n",
              "                                      title  \\\n",
              "1                     PORQUE SI TÚ NO VELAS   \n",
              "2     POEMA DE LA BELLEZA CAUTIVA QUE PERDÍ   \n",
              "3                                 SENCILLEZ   \n",
              "4             Breve Carta a Consuelo Suncín   \n",
              "5                          PASADIZO SECRETO   \n",
              "...                                     ...   \n",
              "5127                                 BOSQUE   \n",
              "5129                        Nada es memoria   \n",
              "5130      Esto es todo lo que deseo para tí   \n",
              "5131                                 Palpar   \n",
              "5132                                EXORDIO   \n",
              "\n",
              "                                                 string  length  \n",
              "1     \\nPORQUE SI TÚ NO VELAS\\n\\n\\nPorque si tú no v...     714  \n",
              "2     \\nPOEMA DE LA BELLEZA CAUTIVA QUE PERDÍ\\n\\n\\nP...     644  \n",
              "3     \\nSENCILLEZ\\n\\n\\nLos dedos de la nieve\\nrepiqu...     251  \n",
              "4     \\nBreve Carta a Consuelo Suncín\\nNaciste en Ar...     390  \n",
              "5     \\nPASADIZO SECRETO\\n\\n\\nOscuridad nieve buitre...     325  \n",
              "...                                                 ...     ...  \n",
              "5127  \\nBOSQUE\\n\\n\\nCruzas por el crepúsculo.\\nEl ai...     425  \n",
              "5129  \\nNada es memoria\\n\\n\\nNada es memoria: todo e...     234  \n",
              "5130  \\nEsto es todo lo que deseo para tí\\n\\nFelicid...     494  \n",
              "5131  \\nPalpar\\n\\nMis manos \\nabren las cortinas de ...     159  \n",
              "5132  \\nEXORDIO\\n\\n\\nY ahora danos\\nuna muerte honor...      77  \n",
              "\n",
              "[3715 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a2b6af9-b35c-4a31-95c7-9a70e0b2b4a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>string</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Marilina Rébora</td>\n",
              "      <td>\\n\\nPorque si tú no velas, vendré como ladrón;...</td>\n",
              "      <td>PORQUE SI TÚ NO VELAS</td>\n",
              "      <td>\\nPORQUE SI TÚ NO VELAS\\n\\n\\nPorque si tú no v...</td>\n",
              "      <td>714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Antonio Colinas</td>\n",
              "      <td>\\n\\nPequeña de mis sueños, por tu piel las pal...</td>\n",
              "      <td>POEMA DE LA BELLEZA CAUTIVA QUE PERDÍ</td>\n",
              "      <td>\\nPOEMA DE LA BELLEZA CAUTIVA QUE PERDÍ\\n\\n\\nP...</td>\n",
              "      <td>644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>José María Hinojosa</td>\n",
              "      <td>\\n\\nLos dedos de la nieve\\nrepiquetearon\\nen e...</td>\n",
              "      <td>SENCILLEZ</td>\n",
              "      <td>\\nSENCILLEZ\\n\\n\\nLos dedos de la nieve\\nrepiqu...</td>\n",
              "      <td>251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rubén Izaguirre Fiallos</td>\n",
              "      <td>Naciste en Armenia,\\npero te fuiste a vivir al...</td>\n",
              "      <td>Breve Carta a Consuelo Suncín</td>\n",
              "      <td>\\nBreve Carta a Consuelo Suncín\\nNaciste en Ar...</td>\n",
              "      <td>390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Leopoldo María Panero</td>\n",
              "      <td>\\n\\nOscuridad nieve buitres desespero oscurida...</td>\n",
              "      <td>PASADIZO SECRETO</td>\n",
              "      <td>\\nPASADIZO SECRETO\\n\\n\\nOscuridad nieve buitre...</td>\n",
              "      <td>325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5127</th>\n",
              "      <td>Ángel González</td>\n",
              "      <td>\\n\\nCruzas por el crepúsculo.\\nEl aire\\ntienes...</td>\n",
              "      <td>BOSQUE</td>\n",
              "      <td>\\nBOSQUE\\n\\n\\nCruzas por el crepúsculo.\\nEl ai...</td>\n",
              "      <td>425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5129</th>\n",
              "      <td>David Escobar Galindo</td>\n",
              "      <td>\\n\\nNada es memoria: todo es invención.\\nLo qu...</td>\n",
              "      <td>Nada es memoria</td>\n",
              "      <td>\\nNada es memoria\\n\\n\\nNada es memoria: todo e...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5130</th>\n",
              "      <td>amistad</td>\n",
              "      <td>\\nFelicidad: Muy dentro de tí.\\nSerenidad: En ...</td>\n",
              "      <td>Esto es todo lo que deseo para tí</td>\n",
              "      <td>\\nEsto es todo lo que deseo para tí\\n\\nFelicid...</td>\n",
              "      <td>494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5131</th>\n",
              "      <td>Octavio Paz</td>\n",
              "      <td>\\nMis manos \\nabren las cortinas de tu ser \\nt...</td>\n",
              "      <td>Palpar</td>\n",
              "      <td>\\nPalpar\\n\\nMis manos \\nabren las cortinas de ...</td>\n",
              "      <td>159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5132</th>\n",
              "      <td>José Ángel Valente</td>\n",
              "      <td>\\n\\nY ahora danos\\nuna muerte honorable,\\nviej...</td>\n",
              "      <td>EXORDIO</td>\n",
              "      <td>\\nEXORDIO\\n\\n\\nY ahora danos\\nuna muerte honor...</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3715 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a2b6af9-b35c-4a31-95c7-9a70e0b2b4a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a2b6af9-b35c-4a31-95c7-9a70e0b2b4a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a2b6af9-b35c-4a31-95c7-9a70e0b2b4a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(poems_filtered['string'])[20])"
      ],
      "metadata": {
        "id": "QRpHDSqjhS56",
        "outputId": "76a6874d-d435-447b-c957-e5f1ba8127c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PALMA SOLA\n",
            "\n",
            "\n",
            "La palma que está en el patio\n",
            "nació sola;\n",
            "creció sin que yo la viera,\n",
            "creció sola;\n",
            "bajo la luna y el sol,\n",
            "vive sola.\n",
            "\n",
            "Con su largo cuerpo fijo,\n",
            "palma sola;\n",
            "sola en el patio sellado,\n",
            "siempre sola,\n",
            "guardián del atardecer,\n",
            "sueña sola.\n",
            "\n",
            "La palma sola soñando,\n",
            "palma sola,\n",
            "que va libre por el viento,\n",
            "libre y sola,\n",
            "suelta de raíz y tierra,\n",
            "suelta y sola,\n",
            "cazadora de las nubes,\n",
            "palma sola,\n",
            "palma sola,\n",
            "palma.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokens para los datos (modelo DeepESP/gpt2-spanish)**"
      ],
      "metadata": {
        "id": "F2gZ7FTsiC70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = poems_filtered"
      ],
      "metadata": {
        "id": "O7yoYPOlM3Rd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"DeepESP/gpt2-spanish\")\n",
        "special_tokens_dict = {\n",
        "    'bos_token': '<BOS>', \n",
        "    'eos_token': '<EOS>', \n",
        "    'pad_token': '<PAD>'}\n",
        "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
      ],
      "metadata": {
        "id": "Oa8z5zEKUDnM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataTokens(Dataset):  \n",
        "    def __init__(self, data, tokenizer, gpt2_type=\"gpt2\", max_length=1000):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        for row in df['string']:\n",
        "          encodings_dict = self.tokenizer('<BOS>' + row + '<EOS>',\n",
        "                                     truncation=True,\n",
        "                                     max_length=max_length,\n",
        "                                     padding='max_length')\n",
        "          self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "          self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx]\n",
        "\n",
        "dataset = DataTokens(df['string'], tokenizer, gpt2_type=\"DeepESP/gpt2-spanish\")"
      ],
      "metadata": {
        "id": "LRJwETkoLBBr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train / Validation Split\n",
        "def train_val_split(split, dataset):\n",
        "    train_size = int(split * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    return train_size, val_size"
      ],
      "metadata": {
        "id": "qkQdY11oVhPS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 73\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "4S7rpqDhWG8G",
        "outputId": "6d67b2ae-6659-4c29-93e7-f97a6aa3895d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9b9a880650>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n",
        "    if packed_tensor is None:\n",
        "        return new_tensor, True, None\n",
        "    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n",
        "        return packed_tensor, False, new_tensor\n",
        "    else:\n",
        "        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n",
        "        return packed_tensor, True, None"
      ],
      "metadata": {
        "id": "4QnKJyd0NSS4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reentrenamiento para el modelo (DeepESP/gpt2-spanish)**"
      ],
      "metadata": {
        "id": "Vw0DxarOic-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configuration = GPT2Config(vocab_size=len(tokenizer), n_positions=1000).from_pretrained(\"DeepESP/gpt2-spanish\", output_hidden_states=True)\n",
        "poem_stanza_model = GPT2LMHeadModel.from_pretrained(\"DeepESP/gpt2-spanish\", config=configuration)\n",
        "poem_stanza_model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "AiZEUhQeXmlN",
        "outputId": "18244368-2055-4bb1-dd8a-c685c5b4ed13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50260, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, model, batch_size=32, epochs=5, learning_rate = 1e-4, eps = 1e-8, warmup_steps=50):\n",
        "    # DataLoaders\n",
        "    poem_line_train_size, poem_line_val_size = train_val_split(0.8, dataset)\n",
        "    poem_line_train_dataset, poem_line_val_dataset = random_split(dataset, [poem_line_train_size, poem_line_val_size])\n",
        "    poem_stanza_train_dataloader = DataLoader(poem_line_train_dataset,\n",
        "                              sampler=RandomSampler(poem_line_train_dataset),\n",
        "                              batch_size=batch_size)\n",
        "    poem_stanza_val_dataloader = DataLoader(poem_line_val_dataset,\n",
        "                                sampler=SequentialSampler(poem_line_val_dataset),\n",
        "                                batch_size=batch_size)\n",
        "    # Modelo\n",
        "    model = model.cuda()\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=eps)\n",
        "    total_steps = len(poem_stanza_train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=warmup_steps,num_training_steps=total_steps)\n",
        "    start_time = time.time()\n",
        "    torch.cuda.empty_cache()\n",
        "    # Entrenamiento\n",
        "    for epoch_i in range(0, epochs):\n",
        "      print(f'Epoch {epoch_i + 1} de {epochs}')\n",
        "      t0 = time.time()\n",
        "      total_train_loss = 0\n",
        "      model.train()\n",
        "      for step, batch in enumerate(poem_stanza_train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        model.zero_grad()\n",
        "        outputs = model(b_input_ids,labels=b_input_ids,attention_mask=b_masks,token_type_ids=None)\n",
        "        loss = outputs[0]\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "      avg_train_loss = total_train_loss / len(poem_stanza_train_dataloader)\n",
        "      training_time = format_time(time.time() - t0)\n",
        "      print(f'Average Training Loss: {avg_train_loss}. Epoch Training Time: {training_time}')\n",
        "      # Validacion\n",
        "      t0 = time.time()\n",
        "      model.eval()\n",
        "      total_eval_loss = 0\n",
        "      nb_eval_steps = 0\n",
        "      for batch in poem_stanza_val_dataloader:\n",
        "        torch.cuda.empty_cache()\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        with torch.no_grad():\n",
        "          outputs  = poem_stanza_model(b_input_ids,attention_mask=b_masks,labels=b_input_ids)\n",
        "          loss = outputs[0]\n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss\n",
        "      avg_val_loss = total_eval_loss / len(poem_stanza_val_dataloader)\n",
        "      print(f'Average Validation Loss: {avg_val_loss}')\n",
        "    print(f'Total Training Time: {format_time(time.time()-start_time)}')\n",
        "    return model"
      ],
      "metadata": {
        "id": "Vu3otaqQO0kO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train(dataset, poem_stanza_model, epochs=10)\n",
        "torch.save(model, 'modelo_gpt2_poesia.pt')"
      ],
      "metadata": {
        "id": "x-bpHQUuRVnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generación de Poesía**"
      ],
      "metadata": {
        "id": "8Tl7dP3niubb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('modelo_gpt2_poesia.pt')"
      ],
      "metadata": {
        "id": "AKftdGuSRz-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model,tokenizer,prompt,length=60,top_p=0.8,temperature=1.):\n",
        "    #prompt = trad_es_en(prompt)[0]['translation_text']\n",
        "    model.eval()\n",
        "    generated_num = 0\n",
        "    generated_list = []\n",
        "    filter_value = -float(\"Inf\")\n",
        "    with torch.no_grad():\n",
        "      entry_finished = False\n",
        "      generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "      for i in range(length):\n",
        "          outputs = model(generated, labels=generated)\n",
        "          loss, logits = outputs[:2]\n",
        "          logits = logits[:, -1, :] / (temperature if temperature > 0 else 1.0)\n",
        "          sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "          cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "          sorted_indices_to_remove = cumulative_probs > top_p\n",
        "          sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "          sorted_indices_to_remove[..., 0] = 0\n",
        "          indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "          logits[:, indices_to_remove] = filter_value\n",
        "          next_token = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1)\n",
        "          generated = torch.cat((generated, next_token), dim=1)\n",
        "          if next_token in tokenizer.encode(\"<|endoftext|>\"): break \n",
        "      output_list = list(generated.squeeze().numpy())\n",
        "      output_text = tokenizer.decode(output_list,skip_special_tokens=True)\n",
        "      generated_list.append(output_text)\n",
        "    #generated_list = trad_en_es(generated_list)[0]['translation_text']  \n",
        "    return generated_list[0]"
      ],
      "metadata": {
        "id": "kqsCgwqCx4z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Palabra = 'CIELO ESTRELLADO'\n",
        "text = generate(model.to('cpu'), tokenizer,Palabra,temperature=0.7,length = 100,top_p = 0.8)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "wLO6WZwJ2_zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Generate2(model,Palabra):\n",
        "  input_ids = tokenizer.encode(Palabra, return_tensors=\"pt\")\n",
        "  output = model.generate(\n",
        "      input_ids,\n",
        "      num_beams=5,\n",
        "      max_length=40,\n",
        "      early_stopping=True,\n",
        "      no_repeat_ngram_size=2,\n",
        "      temperature=1.5\n",
        "  )\n",
        "  output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "  return output"
      ],
      "metadata": {
        "id": "tUxkbcRVP2Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Palabra = 'CIELO ESTRELLADO'\n",
        "text = Generate2(model.to('cpu'),Palabra)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "SQQ_9VMaSEL6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "94e7570899995adebab4ebab5cd3752e227f734c99b4f5f3f0d280f8bef09b63"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('IA')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Gasolina.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}