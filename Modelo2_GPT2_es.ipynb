{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHkYFOFNvqi-"
      },
      "source": [
        "# **Modelo 2 (Generacion de Poemas) GPT2**\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers -U"
      ],
      "metadata": {
        "id": "WGXNdxfBLrwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SAgacGzvqjB"
      },
      "outputs": [],
      "source": [
        "# Basicas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "# Pytorch\n",
        "import torch\n",
        "from torch import nn\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "# Texto\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import random\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm, trange\n",
        "from transformers import pipeline\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "AVAIL_GPUS = min(1, torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Datos**"
      ],
      "metadata": {
        "id": "J1yX23FRe0yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/andreamorgar/poesIA/master/data/poems.csv'\n",
        "poems_df = pd.read_csv(url)\n",
        "poems_df = poems_df.dropna()"
      ],
      "metadata": {
        "id": "1YLm8TDBezt-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar poemas grandes\n",
        "poems_df['string'] = poems_df.apply(lambda row: f'\\n{row[\"title\"]}\\n{row[\"content\"]}', axis=1)\n",
        "poems_df['length'] = poems_df.string.map(len)\n",
        "MAX_POEM_LENGTH=1000\n",
        "poems_filtered = poems_df[poems_df.length<MAX_POEM_LENGTH]\n",
        "_ , poems_filtered = train_test_split(poems_filtered, test_size = 0.5 ,shuffle=True)\n",
        "poems_filtered"
      ],
      "metadata": {
        "id": "1g4lr7TxghDE",
        "outputId": "538900b6-eb09-4155-e7dc-92a631748f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     author  \\\n",
              "1995                        Juan de Arguijo   \n",
              "1007  Santa Teresa de Jesús, Sánchez de Cep   \n",
              "2870                       Gabriela Mistral   \n",
              "2534                         Bertolt Brecht   \n",
              "4919                           Pablo Neruda   \n",
              "...                                     ...   \n",
              "3896                       Oliverio Girondo   \n",
              "5039                       Ángeles Carbajal   \n",
              "3087                        Julia de Burgos   \n",
              "5062                 Gustavo Adolfo Bécquer   \n",
              "2583                    Manuel Altolaguirre   \n",
              "\n",
              "                                                content                 title  \\\n",
              "1995  \\n\\nDel gran Pompeyo el enemigo fuerte\\nllega ...         A JULIO CÉSAR   \n",
              "1007  \\n\\nYa toda me entregué y dí,\\ny de tal suerte...   YA TODA ME ENTREGUÉ   \n",
              "2870  \\nHay países que yo recuerdo \\ncomo recuerdo m...                  Agua   \n",
              "2534       No tenías ninguna,\\nyo sólo una,\\nque amaba.           Debilidades   \n",
              "4919  Cien sonetos de amor\\n\\nAl golpe de la ola con...  Cien sonetos de amor   \n",
              "...                                                 ...                   ...   \n",
              "3896  \\n\\n¿Surgió de bajo tierra?\\n¿Se desprendió de...      APARICIÓN URBANA   \n",
              "5039  Fue corto el viaje:\\nun instante, una eternida...   La tierra prometida   \n",
              "3087  \\nTengo el desesperante silencio de la angusti...  Silencio de angustia   \n",
              "5062  \\nLos invisibles átomos del aire \\nen derredor...                Rima X   \n",
              "2583  \\n\\n¡Qué música del tacto\\nlas caricias contig...          LAS CARICIAS   \n",
              "\n",
              "                                                 string  length  \n",
              "1995  \\nA JULIO CÉSAR\\n\\n\\n\\nDel gran Pompeyo el ene...     518  \n",
              "1007  \\nYA TODA ME ENTREGUÉ\\n\\n\\n\\nYa toda me entreg...     509  \n",
              "2870  \\nAgua\\n\\n\\nHay países que yo recuerdo \\ncomo ...     980  \n",
              "2534  \\nDebilidades\\n\\nNo tenías ninguna,\\nyo sólo u...      56  \n",
              "4919  \\nCien sonetos de amor\\n\\nCien sonetos de amor...     662  \n",
              "...                                                 ...     ...  \n",
              "3896  \\nAPARICIÓN URBANA\\n\\n\\n\\n¿Surgió de bajo tier...     368  \n",
              "5039  \\nLa tierra prometida\\n\\nFue corto el viaje:\\n...     236  \n",
              "3087  \\nSilencio de angustia\\n\\n\\nTengo el desespera...     338  \n",
              "5062  \\nRima X\\n\\n\\nLos invisibles átomos del aire \\...     305  \n",
              "2583  \\nLAS CARICIAS\\n\\n\\n\\n¡Qué música del tacto\\nl...     292  \n",
              "\n",
              "[1858 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ebb71ea1-e25d-4b58-b445-1ad0d617ddef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>string</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>Juan de Arguijo</td>\n",
              "      <td>\\n\\nDel gran Pompeyo el enemigo fuerte\\nllega ...</td>\n",
              "      <td>A JULIO CÉSAR</td>\n",
              "      <td>\\nA JULIO CÉSAR\\n\\n\\n\\nDel gran Pompeyo el ene...</td>\n",
              "      <td>518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>Santa Teresa de Jesús, Sánchez de Cep</td>\n",
              "      <td>\\n\\nYa toda me entregué y dí,\\ny de tal suerte...</td>\n",
              "      <td>YA TODA ME ENTREGUÉ</td>\n",
              "      <td>\\nYA TODA ME ENTREGUÉ\\n\\n\\n\\nYa toda me entreg...</td>\n",
              "      <td>509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2870</th>\n",
              "      <td>Gabriela Mistral</td>\n",
              "      <td>\\nHay países que yo recuerdo \\ncomo recuerdo m...</td>\n",
              "      <td>Agua</td>\n",
              "      <td>\\nAgua\\n\\n\\nHay países que yo recuerdo \\ncomo ...</td>\n",
              "      <td>980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2534</th>\n",
              "      <td>Bertolt Brecht</td>\n",
              "      <td>No tenías ninguna,\\nyo sólo una,\\nque amaba.</td>\n",
              "      <td>Debilidades</td>\n",
              "      <td>\\nDebilidades\\n\\nNo tenías ninguna,\\nyo sólo u...</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4919</th>\n",
              "      <td>Pablo Neruda</td>\n",
              "      <td>Cien sonetos de amor\\n\\nAl golpe de la ola con...</td>\n",
              "      <td>Cien sonetos de amor</td>\n",
              "      <td>\\nCien sonetos de amor\\n\\nCien sonetos de amor...</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3896</th>\n",
              "      <td>Oliverio Girondo</td>\n",
              "      <td>\\n\\n¿Surgió de bajo tierra?\\n¿Se desprendió de...</td>\n",
              "      <td>APARICIÓN URBANA</td>\n",
              "      <td>\\nAPARICIÓN URBANA\\n\\n\\n\\n¿Surgió de bajo tier...</td>\n",
              "      <td>368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5039</th>\n",
              "      <td>Ángeles Carbajal</td>\n",
              "      <td>Fue corto el viaje:\\nun instante, una eternida...</td>\n",
              "      <td>La tierra prometida</td>\n",
              "      <td>\\nLa tierra prometida\\n\\nFue corto el viaje:\\n...</td>\n",
              "      <td>236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3087</th>\n",
              "      <td>Julia de Burgos</td>\n",
              "      <td>\\nTengo el desesperante silencio de la angusti...</td>\n",
              "      <td>Silencio de angustia</td>\n",
              "      <td>\\nSilencio de angustia\\n\\n\\nTengo el desespera...</td>\n",
              "      <td>338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5062</th>\n",
              "      <td>Gustavo Adolfo Bécquer</td>\n",
              "      <td>\\nLos invisibles átomos del aire \\nen derredor...</td>\n",
              "      <td>Rima X</td>\n",
              "      <td>\\nRima X\\n\\n\\nLos invisibles átomos del aire \\...</td>\n",
              "      <td>305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2583</th>\n",
              "      <td>Manuel Altolaguirre</td>\n",
              "      <td>\\n\\n¡Qué música del tacto\\nlas caricias contig...</td>\n",
              "      <td>LAS CARICIAS</td>\n",
              "      <td>\\nLAS CARICIAS\\n\\n\\n\\n¡Qué música del tacto\\nl...</td>\n",
              "      <td>292</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1858 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebb71ea1-e25d-4b58-b445-1ad0d617ddef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ebb71ea1-e25d-4b58-b445-1ad0d617ddef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ebb71ea1-e25d-4b58-b445-1ad0d617ddef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(poems_filtered['string'])[0])"
      ],
      "metadata": {
        "id": "QRpHDSqjhS56",
        "outputId": "28e7696f-c207-4d41-f28a-1b9759c91775",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A JULIO CÉSAR\n",
            "\n",
            "\n",
            "\n",
            "Del gran Pompeyo el enemigo fuerte\n",
            "llega en oscura noche al pobre techo,\n",
            "do Amiclas con seguro y libre pecho\n",
            "ni teme daño ni recela muerte.\n",
            "\n",
            "Ya que llamar segunda vez advierte,\n",
            "rogado deja el mal compuesto lecho,\n",
            "y en frágil barca el peligroso estrecho\n",
            "rompe, presagio de siniestra suerte.\n",
            "\n",
            "Brama furioso el mar sintiendo el peso\n",
            "que sostiene, y al tímido piloto\n",
            "César anima, y dice: «Rema amigo,\n",
            "\n",
            "»Rema; no temas infeliz suceso\n",
            "por más que te contrasten Euro y Noto;\n",
            "la fortuna de César va contigo».\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokens para los datos (modelo DeepESP/gpt2-spanish)**"
      ],
      "metadata": {
        "id": "F2gZ7FTsiC70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = poems_filtered"
      ],
      "metadata": {
        "id": "O7yoYPOlM3Rd"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataTokens(Dataset):  \n",
        "    def __init__(self, control_code, truncate=False, gpt2_type=\"gpt2\", max_length=1024):\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n",
        "        self.lyrics = []\n",
        "        for row in df['string']:\n",
        "          self.row = f\"<|{control_code}|>{row[:max_length]}<|endoftext|>\"\n",
        "          self.lyrics.append(torch.tensor(self.tokenizer.encode(self.row))) \n",
        "        if truncate:\n",
        "            self.lyrics = self.lyrics[:20000]\n",
        "        self.lyrics_count = len(self.lyrics)\n",
        "    def __len__(self):\n",
        "        return self.lyrics_count\n",
        "    def __getitem__(self, item):\n",
        "        return self.lyrics[item]\n",
        "dataset = DataTokens(df['string'], truncate=True, gpt2_type=\"DeepESP/gpt2-spanish\")"
      ],
      "metadata": {
        "id": "LRJwETkoLBBr"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(pretrained_weights)\n",
        "def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n",
        "    if packed_tensor is None:\n",
        "        return new_tensor, True, None\n",
        "    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n",
        "        return packed_tensor, False, new_tensor\n",
        "    else:\n",
        "        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n",
        "        return packed_tensor, True, None"
      ],
      "metadata": {
        "id": "4QnKJyd0NSS4"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reentrenamiento para el modelo (DeepESP/gpt2-spanish)**"
      ],
      "metadata": {
        "id": "Vw0DxarOic-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(pretrained_weights, pad_token_id=tokenizer.eos_token_id)\n",
        "def train(dataset, model, batch_size=32, epochs=5, lr=2e-5, warmup_steps=200):\n",
        "    device=torch.device(\"cuda\")\n",
        "    model = model.cuda()\n",
        "    model.train()\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1)\n",
        "    train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "    loss=0\n",
        "    accumulating_batch_count = 0\n",
        "    input_tensor = None\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Training epoch {epoch}\")\n",
        "        print(loss)\n",
        "        for idx, entry in tqdm(enumerate(train_dataloader)):\n",
        "            (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 768)\n",
        "            if carry_on and idx != len(train_dataloader) - 1:\n",
        "                continue\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            outputs = model(input_tensor, labels=input_tensor)\n",
        "            loss = outputs[0]\n",
        "            loss.backward()\n",
        "            if (accumulating_batch_count % batch_size) == 0:\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "                model.zero_grad()\n",
        "            accumulating_batch_count += 1\n",
        "            input_tensor = None\n",
        "    return model"
      ],
      "metadata": {
        "id": "Vu3otaqQO0kO"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train(dataset, model, epochs=5)\n",
        "torch.save(model, 'modelo_gpt2_poesia.pt')"
      ],
      "metadata": {
        "id": "x-bpHQUuRVnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generación de Poesía**"
      ],
      "metadata": {
        "id": "8Tl7dP3niubb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('modelo_gpt2_poesia.pt')"
      ],
      "metadata": {
        "id": "AKftdGuSRz-K"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model,tokenizer,prompt,length=60,top_p=0.8,temperature=1.):\n",
        "    #prompt = trad_es_en(prompt)[0]['translation_text']\n",
        "    model.eval()\n",
        "    generated_num = 0\n",
        "    generated_list = []\n",
        "    filter_value = -float(\"Inf\")\n",
        "    with torch.no_grad():\n",
        "      entry_finished = False\n",
        "      generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "      for i in range(length):\n",
        "          outputs = model(generated, labels=generated)\n",
        "          loss, logits = outputs[:2]\n",
        "          logits = logits[:, -1, :] / (temperature if temperature > 0 else 1.0)\n",
        "          sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "          cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "          sorted_indices_to_remove = cumulative_probs > top_p\n",
        "          sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "          sorted_indices_to_remove[..., 0] = 0\n",
        "          indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "          logits[:, indices_to_remove] = filter_value\n",
        "          next_token = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1)\n",
        "          generated = torch.cat((generated, next_token), dim=1)\n",
        "          if next_token in tokenizer.encode(\"<|endoftext|>\"): break \n",
        "      output_list = list(generated.squeeze().numpy())\n",
        "      output_text = tokenizer.decode(output_list,skip_special_tokens=True)\n",
        "      generated_list.append(output_text)\n",
        "    #generated_list = trad_en_es(generated_list)[0]['translation_text']  \n",
        "    return generated_list[0]"
      ],
      "metadata": {
        "id": "kqsCgwqCx4z1"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Palabra = 'CIELO ESTRELLADO'\n",
        "text = generate(model.to('cpu'), tokenizer,Palabra,temperature=0.7,length = 100,top_p = 0.8)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "wLO6WZwJ2_zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Generate2(model,Palabra):\n",
        "  input_ids = tokenizer.encode(Palabra, return_tensors=\"pt\")\n",
        "  output = model.generate(\n",
        "      input_ids,\n",
        "      num_beams=5,\n",
        "      max_length=40,\n",
        "      early_stopping=True,\n",
        "      no_repeat_ngram_size=2,\n",
        "      temperature=1.5\n",
        "  )\n",
        "  output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "  return output"
      ],
      "metadata": {
        "id": "tUxkbcRVP2Fn"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Palabra = 'CIELO ESTRELLADO'\n",
        "text = Generate2(model.to('cpu'),Palabra)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "SQQ_9VMaSEL6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "94e7570899995adebab4ebab5cd3752e227f734c99b4f5f3f0d280f8bef09b63"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('IA')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Gasolina.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}